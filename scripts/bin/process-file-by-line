#! /usr/bin/env bash

# Utility for something I often need. Process a file line-by-line, removing the line on successful completion.
# If `cmd` exits with exit code 0 the line is moved to `file.sucess`. If it exists with another exit code
# it is moved to `file.failure`. This handles aborts gracefully (the command will abort, the line will
# remain in the original file).
# It can even handle additions and removals to the file at runtime.

# Typical usage: Have some queue of files to process. That is usually a long-running unattended process.
# Failures can be dealt with after the fact, the process can be aboarted and picked up again any time.

if (( $# < 1 )); then
	echo 'Usage: `process-file-line-by-line <cmd> <file>`' >&2
	echo '`file` defaults to `queue.txt`, `cmd` takes one argument (the line).' >&2
	exit 1
fi

cmd="${1}"
queue="${2:-queue.txt}"
lines="$( wc -l "$queue")"
current_line_no=0
logdir="${queue}-logs"

while [ -s "$queue" ]; do
	cur="$(head -n 1 "$queue")"
	cur_hash="$(sha256sum <<< "$cur" | awk '{print $1}')"
	(( current_line_no += 1 ))

	echo "$(date -Iseconds): Processing '$cur' ($current_line_no/$lines)"

	mkdir -p "${logdir}"
	logfile="${logdir}/${cur_hash}.log"
	echo "$cur" > "$logfile"
	if bash -c "$cmd '$cur'" >> "$logfile" 2>&1; then
		echo "$cur" >> "$queue.sucess"
		rm "$logfile"
	else
		echo "Failure. Logs in $logfile."
		cat "$logfile"
		echo "$cur" >> "$queue.failure"
	fi
	# remove first line of queue
	cp "$queue" "$queue.bak"
	tail -n+2 "$queue.bak" > "$queue"
	rm "$queue.bak"
done

rmdir --ignore-fail-on-non-empty "$logdir"
